{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNzj3fAFbq0FdrPzLUZXLFV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferhat00/LLM/blob/main/Satellite_Imagery_Cushing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klIwSdMSZDts",
        "outputId": "5790768a-8c95-40c3-d969-71c9adbe2350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting astropy\n",
            "  Downloading astropy-6.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from astropy) (1.26.4)\n",
            "Collecting pyerfa>=2.0.1.1 (from astropy)\n",
            "  Downloading pyerfa-2.0.1.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting astropy-iers-data>=0.2024.10.28.0.34.7 (from astropy)\n",
            "  Downloading astropy_iers_data-0.2024.12.23.0.33.24-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.10/dist-packages (from astropy) (6.0.2)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from astropy) (24.2)\n",
            "Downloading astropy-6.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astropy_iers_data-0.2024.12.23.0.33.24-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyerfa-2.0.1.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.7/738.7 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyerfa, astropy-iers-data, astropy\n",
            "Successfully installed astropy-6.1.7 astropy-iers-data-0.2024.12.23.0.33.24 pyerfa-2.0.1.5\n"
          ]
        }
      ],
      "source": [
        "!pip install astropy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shapely"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKoGKx2JaZzQ",
        "outputId": "ae55a0a1-de7d-48df-f27b-2346b2f6853e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shapely\n",
            "  Downloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely) (1.26.4)\n",
            "Downloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/2.5 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: shapely\n",
            "Successfully installed shapely-2.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RwGZRb0dzh9",
        "outputId": "39d621eb-cde1-48e5-8152-18f40fff67d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (2024.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from datetime import datetime\n",
        "import pytz # Import the pytz module\n",
        "from astropy.coordinates import get_sun, EarthLocation, AltAz\n",
        "import astropy.units as u\n",
        "from shapely.geometry import Polygon\n",
        "import pandas as pd\n",
        "from astropy.time import Time # Import the Time class\n",
        "\n",
        "class OilTankAnalyzer:\n",
        "    def __init__(self):\n",
        "        # Cushing, Oklahoma coordinates\n",
        "        self.latitude = 35.9828  # N\n",
        "        self.longitude = -96.7534  # W\n",
        "        self.location = EarthLocation(lat=self.latitude*u.deg,\n",
        "                                    lon=self.longitude*u.deg,\n",
        "                                    height=300*u.m)\n",
        "        self.timezone = pytz.timezone('US/Central') # Define the timezone, here set to 'US/Central' for Cushing, Oklahoma\n",
        "\n",
        "    def calculate_sun_position(self, timestamp):\n",
        "        \"\"\"Calculate sun's altitude and azimuth for shadow analysis.\"\"\"\n",
        "        # Convert local time to UTC for astronomical calculations\n",
        "        if timestamp.tzinfo is None:\n",
        "            local_time = self.timezone.localize(timestamp)\n",
        "        else:\n",
        "            local_time = timestamp.astimezone(self.timezone)\n",
        "\n",
        "        utc_time = local_time.astimezone(pytz.UTC)\n",
        "        # Convert datetime to astropy Time object\n",
        "        utc_time = Time(utc_time, scale='utc') # Convert to astropy Time object with scale='utc'\n",
        "        altaz = AltAz(location=self.location, obstime=utc_time)\n",
        "        sun = get_sun(utc_time)\n",
        "        sun_altaz = sun.transform_to(altaz)\n",
        "        return sun_altaz.alt.deg, sun_altaz.az.deg\n",
        "\n",
        "    def detect_tanks(self, image):\n",
        "        \"\"\"\n",
        "        Detect circular tanks using Hough Circle Transform\n",
        "        Returns: List of (x, y, radius) for each detected tank\n",
        "        \"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        blurred = cv2.GaussianBlur(gray, (9, 9), 2)\n",
        "\n",
        "        # Detect circles using Hough Circle Transform\n",
        "        circles = cv2.HoughCircles(\n",
        "            blurred,\n",
        "            cv2.HOUGH_GRADIENT,\n",
        "            dp=1,\n",
        "            minDist=50,\n",
        "            param1=50,\n",
        "            param2=30,\n",
        "            minRadius=20,\n",
        "            maxRadius=100\n",
        "        )\n",
        "\n",
        "        if circles is not None:\n",
        "            return np.round(circles[0, :]).astype(int)\n",
        "        return []\n",
        "\n",
        "    def analyze_shadow(self, image, tank_info, sun_alt, sun_az):\n",
        "        \"\"\"\n",
        "        Analyze shadow pattern to estimate tank fill level\n",
        "        Args:\n",
        "            image: Satellite image\n",
        "            tank_info: (x, y, radius) of tank\n",
        "            sun_alt: Sun altitude in degrees\n",
        "            sun_az: Sun azimuth in degrees\n",
        "        Returns:\n",
        "            Estimated fill percentage\n",
        "        \"\"\"\n",
        "        x, y, r = tank_info\n",
        "\n",
        "        # Create mask for shadow detection\n",
        "        mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
        "        cv2.circle(mask, (x, y), r, 255, -1)\n",
        "\n",
        "        # Convert to HSV for better shadow detection\n",
        "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "        shadow_mask = cv2.inRange(hsv,\n",
        "                                np.array([0, 0, 0]),\n",
        "                                np.array([180, 255, 70]))\n",
        "\n",
        "        # Combine tank mask with shadow detection\n",
        "        shadow_region = cv2.bitwise_and(shadow_mask, mask)\n",
        "\n",
        "        # Calculate expected shadow direction based on sun position\n",
        "        shadow_angle = sun_az + 180  # Shadow falls opposite to sun\n",
        "        shadow_length = r * np.tan(np.radians(90 - sun_alt))\n",
        "\n",
        "        # Create expected shadow polygon\n",
        "        shadow_end_x = x + shadow_length * np.cos(np.radians(shadow_angle))\n",
        "        shadow_end_y = y + shadow_length * np.sin(np.radians(shadow_angle))\n",
        "\n",
        "        # Compare actual shadow with expected shadow\n",
        "        expected_shadow = Polygon([\n",
        "            (x, y),\n",
        "            (shadow_end_x, shadow_end_y),\n",
        "            (shadow_end_x + r, shadow_end_y),\n",
        "            (x + r, y)\n",
        "        ])\n",
        "\n",
        "        actual_shadow = np.where(shadow_region > 0)\n",
        "        actual_shadow_area = len(actual_shadow[0])\n",
        "\n",
        "        # Calculate fill level based on shadow pattern\n",
        "        max_shadow_area = np.pi * r * shadow_length\n",
        "        shadow_ratio = actual_shadow_area / max_shadow_area\n",
        "\n",
        "        # Adjust for floating roof tanks\n",
        "        fill_percentage = 100 * (1 - shadow_ratio)\n",
        "\n",
        "        return fill_percentage\n",
        "\n",
        "    def estimate_volume(self, tank_radius, fill_percentage):\n",
        "        \"\"\"\n",
        "        Estimate stored volume based on tank dimensions and fill level\n",
        "        Args:\n",
        "            tank_radius: Radius in pixels (needs conversion to meters)\n",
        "            fill_percentage: Estimated fill percentage\n",
        "        Returns:\n",
        "            Estimated volume in barrels\n",
        "        \"\"\"\n",
        "        # Convert pixel radius to meters (approximate conversion based on typical tank sizes)\n",
        "        pixels_per_meter = 0.5  # This needs calibration based on image resolution\n",
        "        radius_meters = tank_radius * pixels_per_meter\n",
        "\n",
        "        # Standard tank height (most Cushing tanks are ~40-50 feet tall)\n",
        "        height_meters = 14  # approximately 45 feet\n",
        "\n",
        "        # Calculate total tank volume in cubic meters\n",
        "        total_volume = np.pi * radius_meters**2 * height_meters\n",
        "\n",
        "        # Convert to barrels (1 cubic meter = 6.2898 barrels)\n",
        "        total_barrels = total_volume * 6.2898\n",
        "\n",
        "        # Apply fill percentage\n",
        "        actual_barrels = total_barrels * (fill_percentage / 100)\n",
        "\n",
        "        return actual_barrels\n",
        "\n",
        "    def analyze_image(self, image_path, timestamp):\n",
        "        \"\"\"\n",
        "        Main function to analyze satellite image and estimate storage volumes\n",
        "        Args:\n",
        "            image_path: Path to satellite image\n",
        "            timestamp: DateTime object of image capture\n",
        "        Returns:\n",
        "            DataFrame with tank locations and estimated volumes\n",
        "        \"\"\"\n",
        "        # Load and preprocess image\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise ValueError(\"Could not load image\")\n",
        "\n",
        "        # Get sun position\n",
        "        sun_alt, sun_az = self.calculate_sun_position(timestamp)\n",
        "\n",
        "        # Detect tanks\n",
        "        tanks = self.detect_tanks(image)\n",
        "\n",
        "        results = []\n",
        "        for tank in tanks:\n",
        "            x, y, r = tank\n",
        "            fill_percentage = self.analyze_shadow(image, tank, sun_alt, sun_az)\n",
        "            volume = self.estimate_volume(r, fill_percentage)\n",
        "\n",
        "            results.append({\n",
        "                'x': x,\n",
        "                'y': y,\n",
        "                'radius': r,\n",
        "                'fill_percentage': fill_percentage,\n",
        "                'estimated_volume': volume\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "def main():\n",
        "    analyzer = OilTankAnalyzer()\n",
        "    timestamp = datetime.now()  # Replace with actual image timestamp\n",
        "    results = analyzer.analyze_image('/content/gas.jpg', timestamp)\n",
        "    print(f\"Total estimated storage: {results['estimated_volume'].sum():,.0f} barrels\")\n",
        "    print(f\"Fill percentage: {results['fill_percentage'].mean():,.0f} %\")\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSyP3zoSbvlz",
        "outputId": "cde859bf-961b-4327-d165-642386e20116"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total estimated storage: 7,599,171 barrels\n",
            "Fill percentage: 99 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from astropy.coordinates import get_sun, EarthLocation, AltAz\n",
        "import astropy.units as u\n",
        "from astropy.time import Time\n",
        "import pandas as pd\n",
        "from torchvision import transforms, models\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "class TankDetectionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TankDetectionNet, self).__init__()\n",
        "        # Use ResNet50 as backbone, pretrained on ImageNet\n",
        "        self.backbone = models.resnet50(pretrained=True)\n",
        "\n",
        "        # Modify final layers for tank detection\n",
        "        num_features = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Identity()\n",
        "\n",
        "        # Custom detection heads\n",
        "        self.location_head = nn.Sequential(\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 4)  # x, y, width, height\n",
        "        )\n",
        "\n",
        "        self.confidence_head = nn.Sequential(\n",
        "            nn.Linear(num_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "        locations = self.location_head(features)\n",
        "        confidence = self.confidence_head(features)\n",
        "        return locations, confidence\n",
        "\n",
        "class ShadowAnalysisNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ShadowAnalysisNet, self).__init__()\n",
        "        # U-Net style architecture for shadow segmentation\n",
        "        self.encoder = models.resnet34(pretrained=True)\n",
        "        self.encoder.fc = nn.Identity()\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 1, kernel_size=2, stride=2),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        features = features.view(-1, 512, 7, 7)  # Reshape for decoder\n",
        "        shadow_mask = self.decoder(features)\n",
        "        return shadow_mask\n",
        "\n",
        "class VolumeEstimationNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VolumeEstimationNet, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(7, 128),  # Input: shadow metrics + sun position + tank dimensions\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 1)    # Output: fill percentage\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "class MLTankAnalyzer:\n",
        "    def __init__(self, model_weights_path=None):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Initialize models\n",
        "        self.tank_detector = TankDetectionNet().to(self.device)\n",
        "        self.shadow_analyzer = ShadowAnalysisNet().to(self.device)\n",
        "        self.volume_estimator = VolumeEstimationNet().to(self.device)\n",
        "\n",
        "        # Load pre-trained weights if provided\n",
        "        if model_weights_path:\n",
        "            self.load_weights(model_weights_path)\n",
        "\n",
        "        # Cushing coordinates\n",
        "        self.latitude = 35.9828  # N\n",
        "        self.longitude = -96.7534  # W\n",
        "        self.location = EarthLocation(lat=self.latitude*u.deg,\n",
        "                                    lon=self.longitude*u.deg,\n",
        "                                    height=300*u.m)\n",
        "\n",
        "        # Image preprocessing\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                              std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def load_weights(self, weights_path):\n",
        "        \"\"\"Load pre-trained weights for all models\"\"\"\n",
        "        weights = torch.load(weights_path, map_location=self.device)\n",
        "        self.tank_detector.load_state_dict(weights['tank_detector'])\n",
        "        self.shadow_analyzer.load_state_dict(weights['shadow_analyzer'])\n",
        "        self.volume_estimator.load_state_dict(weights['volume_estimator'])\n",
        "\n",
        "    def calculate_sun_position(self, timestamp):\n",
        "        \"\"\"Calculate sun's altitude and azimuth for shadow analysis\"\"\"\n",
        "        if timestamp.tzinfo is None:\n",
        "            utc_time = Time(utc_time, scale='utc')\n",
        "        else:\n",
        "            utc_time = Time(timestamp.astimezone(pytz.UTC), scale='utc')\n",
        "\n",
        "        altaz = AltAz(location=self.location, obstime=utc_time)\n",
        "        sun = get_sun(utc_time)\n",
        "        sun_altaz = sun.transform_to(altaz)\n",
        "        return sun_altaz.alt.deg, sun_altaz.az.deg\n",
        "\n",
        "    def detect_tanks(self, image):\n",
        "        \"\"\"Detect tanks using the neural network\"\"\"\n",
        "        self.tank_detector.eval()\n",
        "        with torch.no_grad():\n",
        "            img_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
        "            locations, confidence = self.tank_detector(img_tensor)\n",
        "\n",
        "            # Filter detections by confidence\n",
        "            valid_detections = confidence.squeeze() > 0.5\n",
        "            locations = locations[valid_detections]\n",
        "\n",
        "            return locations.cpu().numpy()\n",
        "\n",
        "    def analyze_shadow(self, image, tank_location, sun_alt, sun_az):\n",
        "        \"\"\"Analyze shadows using the shadow analysis network\"\"\"\n",
        "        self.shadow_analyzer.eval()\n",
        "        with torch.no_grad():\n",
        "            # Extract tank region\n",
        "            x, y, w, h = tank_location\n",
        "            tank_region = image[int(y):int(y+h), int(x):int(x+w)]\n",
        "\n",
        "            # Preprocess and get shadow mask\n",
        "            tank_tensor = self.transform(tank_region).unsqueeze(0).to(self.device)\n",
        "            shadow_mask = self.shadow_analyzer(tank_tensor)\n",
        "\n",
        "            # Calculate shadow metrics\n",
        "            shadow_area = shadow_mask.sum().item()\n",
        "            shadow_perimeter = self.calculate_shadow_perimeter(shadow_mask)\n",
        "            shadow_direction = self.calculate_shadow_direction(shadow_mask)\n",
        "\n",
        "            return shadow_area, shadow_perimeter, shadow_direction\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_shadow_perimeter(shadow_mask):\n",
        "        \"\"\"Calculate the perimeter of the shadow\"\"\"\n",
        "        shadow_np = shadow_mask.cpu().numpy().squeeze()\n",
        "        edges = cv2.Canny(shadow_np.astype(np.uint8), 100, 200)\n",
        "        return np.sum(edges > 0)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_shadow_direction(shadow_mask):\n",
        "        \"\"\"Calculate the primary direction of the shadow\"\"\"\n",
        "        shadow_np = shadow_mask.cpu().numpy().squeeze()\n",
        "        moments = cv2.moments(shadow_np.astype(np.uint8))\n",
        "        if moments['mu20'] + moments['mu02'] != 0:\n",
        "            theta = 0.5 * np.arctan2(2 * moments['mu11'],\n",
        "                                   moments['mu20'] - moments['mu02'])\n",
        "            return np.degrees(theta)\n",
        "        return 0\n",
        "\n",
        "    def estimate_volume(self, shadow_metrics, tank_dims, sun_position):\n",
        "        \"\"\"Estimate tank volume using the volume estimation network\"\"\"\n",
        "        self.volume_estimator.eval()\n",
        "        with torch.no_grad():\n",
        "            # Combine all features\n",
        "            features = np.concatenate([\n",
        "                shadow_metrics,  # shadow area, perimeter, direction\n",
        "                tank_dims,       # width, height\n",
        "                sun_position     # altitude, azimuth\n",
        "            ])\n",
        "\n",
        "            # Normalize features\n",
        "            features_normalized = self.scaler.transform(features.reshape(1, -1))\n",
        "            features_tensor = torch.FloatTensor(features_normalized).to(self.device)\n",
        "\n",
        "            # Predict fill percentage\n",
        "            fill_percentage = self.volume_estimator(features_tensor).item()\n",
        "\n",
        "            # Calculate volume in barrels\n",
        "            tank_radius = tank_dims[0] / 2\n",
        "            height_meters = 14  # standard tank height\n",
        "            total_volume = np.pi * (tank_radius ** 2) * height_meters\n",
        "            volume_barrels = total_volume * 6.2898 * fill_percentage\n",
        "\n",
        "            return fill_percentage * 100, volume_barrels\n",
        "\n",
        "    def analyze_image(self, image_path, timestamp):\n",
        "        \"\"\"Main function to analyze satellite image and estimate storage volumes\"\"\"\n",
        "        # Load and preprocess image\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise ValueError(\"Could not load image\")\n",
        "\n",
        "        # Get sun position\n",
        "        sun_alt, sun_az = self.calculate_sun_position(timestamp)\n",
        "\n",
        "        # Detect tanks\n",
        "        tank_locations = self.detect_tanks(image)\n",
        "\n",
        "        results = []\n",
        "        for location in tank_locations:\n",
        "            # Analyze shadow\n",
        "            shadow_metrics = self.analyze_shadow(image, location, sun_alt, sun_az)\n",
        "\n",
        "            # Estimate volume\n",
        "            tank_dims = location[2:]  # width, height\n",
        "            sun_position = np.array([sun_alt, sun_az])\n",
        "            fill_percentage, volume = self.estimate_volume(\n",
        "                np.array(shadow_metrics),\n",
        "                tank_dims,\n",
        "                sun_position\n",
        "            )\n",
        "\n",
        "            results.append({\n",
        "                'x': location[0],\n",
        "                'y': location[1],\n",
        "                'width': location[2],\n",
        "                'height': location[3],\n",
        "                'fill_percentage': fill_percentage,\n",
        "                'estimated_volume': volume\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "def main():\n",
        "    analyzer = MLTankAnalyzer()\n",
        "    # Get current time in UTC\n",
        "    timestamp = datetime.now(pytz.UTC)\n",
        "    image_path = '/content/gas.jpg'\n",
        "\n",
        "    try:\n",
        "        results = analyzer.analyze_image(image_path, timestamp)\n",
        "        central_time = timestamp.astimezone(pytz.timezone('America/Chicago'))\n",
        "        print(f\"Analysis timestamp (Central Time): {central_time}\")\n",
        "        print(f\"Total estimated storage: {results['estimated_volume'].sum():,.0f} barrels\")\n",
        "        print(\"\\nIndividual tank details:\")\n",
        "        print(results.to_string(index=False))\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Analysis failed: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE642frjfMkT",
        "outputId": "ef27f393-8126-4218-df0a-f20f03df9b52"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis timestamp (Central Time): 2024-12-29 02:22:51.847909-06:00\n",
            "Analysis failed: 'estimated_volume'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from astropy.coordinates import get_sun, EarthLocation, AltAz\n",
        "from astropy.time import Time\n",
        "import astropy.units as u\n",
        "import pandas as pd\n",
        "from torchvision import transforms, models\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "class TankDetectionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TankDetectionNet, self).__init__()\n",
        "        # Use ResNet50 as backbone with updated weights parameter\n",
        "        self.backbone = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "\n",
        "        # Modify final layers for tank detection\n",
        "        num_features = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Identity()\n",
        "\n",
        "        # Custom detection heads\n",
        "        self.location_head = nn.Sequential(\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 4)  # x, y, width, height\n",
        "        )\n",
        "\n",
        "        self.confidence_head = nn.Sequential(\n",
        "            nn.Linear(num_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "        locations = self.location_head(features)\n",
        "        confidence = self.confidence_head(features)\n",
        "        return locations, confidence\n",
        "\n",
        "class ShadowAnalysisNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ShadowAnalysisNet, self).__init__()\n",
        "        # U-Net style architecture for shadow segmentation\n",
        "        self.encoder = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
        "        self.encoder.fc = nn.Identity()\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 1, kernel_size=2, stride=2),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        features = features.view(-1, 512, 7, 7)  # Reshape for decoder\n",
        "        shadow_mask = self.decoder(features)\n",
        "        return shadow_mask\n",
        "\n",
        "class VolumeEstimationNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VolumeEstimationNet, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(7, 128),  # Input: shadow metrics + sun position + tank dimensions\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 1)    # Output: fill percentage\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "class MLTankAnalyzer:\n",
        "    def __init__(self, model_weights_path=None):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Initialize models\n",
        "        self.tank_detector = TankDetectionNet().to(self.device)\n",
        "        self.shadow_analyzer = ShadowAnalysisNet().to(self.device)\n",
        "        self.volume_estimator = VolumeEstimationNet().to(self.device)\n",
        "\n",
        "        # Load pre-trained weights if provided\n",
        "        if model_weights_path:\n",
        "            self.load_weights(model_weights_path)\n",
        "\n",
        "        # Cushing coordinates\n",
        "        self.latitude = 35.9828  # N\n",
        "        self.longitude = -96.7534  # W\n",
        "        self.location = EarthLocation(lat=self.latitude*u.deg,\n",
        "                                    lon=self.longitude*u.deg,\n",
        "                                    height=300*u.m)\n",
        "\n",
        "        # Image preprocessing\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                              std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def load_weights(self, weights_path):\n",
        "        \"\"\"Load pre-trained weights for all models\"\"\"\n",
        "        weights = torch.load(weights_path, map_location=self.device)\n",
        "        self.tank_detector.load_state_dict(weights['tank_detector'])\n",
        "        self.shadow_analyzer.load_state_dict(weights['shadow_analyzer'])\n",
        "        self.volume_estimator.load_state_dict(weights['volume_estimator'])\n",
        "\n",
        "    def calculate_sun_position(self, timestamp):\n",
        "        \"\"\"Calculate sun's altitude and azimuth for shadow analysis\"\"\"\n",
        "        from astropy.time import Time\n",
        "\n",
        "        # Convert datetime to Astropy Time object\n",
        "        if timestamp.tzinfo is None:\n",
        "            utc_time = pytz.UTC.localize(timestamp)\n",
        "        else:\n",
        "            utc_time = timestamp.astimezone(pytz.UTC)\n",
        "\n",
        "        time = Time(utc_time)\n",
        "\n",
        "        # Calculate sun position\n",
        "        altaz = AltAz(location=self.location, obstime=time)\n",
        "        sun = get_sun(time)\n",
        "        sun_altaz = sun.transform_to(altaz)\n",
        "        return sun_altaz.alt.deg, sun_altaz.az.deg\n",
        "\n",
        "    def detect_tanks(self, image):\n",
        "        \"\"\"Detect tanks using the neural network\"\"\"\n",
        "        self.tank_detector.eval()\n",
        "        with torch.no_grad():\n",
        "            img_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
        "            locations, confidence = self.tank_detector(img_tensor)\n",
        "\n",
        "            # Filter detections by confidence\n",
        "            valid_detections = confidence.squeeze() > 0.5\n",
        "            locations = locations[valid_detections]\n",
        "\n",
        "            return locations.cpu().numpy()\n",
        "\n",
        "    def analyze_shadow(self, image, tank_location, sun_alt, sun_az):\n",
        "        \"\"\"Analyze shadows using the shadow analysis network\"\"\"\n",
        "        self.shadow_analyzer.eval()\n",
        "        with torch.no_grad():\n",
        "            # Extract tank region\n",
        "            x, y, w, h = tank_location\n",
        "            tank_region = image[int(y):int(y+h), int(x):int(x+w)]\n",
        "\n",
        "            # Preprocess and get shadow mask\n",
        "            tank_tensor = self.transform(tank_region).unsqueeze(0).to(self.device)\n",
        "            shadow_mask = self.shadow_analyzer(tank_tensor)\n",
        "\n",
        "            # Calculate shadow metrics\n",
        "            shadow_area = shadow_mask.sum().item()\n",
        "            shadow_perimeter = self.calculate_shadow_perimeter(shadow_mask)\n",
        "            shadow_direction = self.calculate_shadow_direction(shadow_mask)\n",
        "\n",
        "            return shadow_area, shadow_perimeter, shadow_direction\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_shadow_perimeter(shadow_mask):\n",
        "        \"\"\"Calculate the perimeter of the shadow\"\"\"\n",
        "        shadow_np = shadow_mask.cpu().numpy().squeeze()\n",
        "        edges = cv2.Canny(shadow_np.astype(np.uint8), 100, 200)\n",
        "        return np.sum(edges > 0)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_shadow_direction(shadow_mask):\n",
        "        \"\"\"Calculate the primary direction of the shadow\"\"\"\n",
        "        shadow_np = shadow_mask.cpu().numpy().squeeze()\n",
        "        moments = cv2.moments(shadow_np.astype(np.uint8))\n",
        "        if moments['mu20'] + moments['mu02'] != 0:\n",
        "            theta = 0.5 * np.arctan2(2 * moments['mu11'],\n",
        "                                   moments['mu20'] - moments['mu02'])\n",
        "            return np.degrees(theta)\n",
        "        return 0\n",
        "\n",
        "    def estimate_volume(self, shadow_metrics, tank_dims, sun_position):\n",
        "        \"\"\"Estimate tank volume using the volume estimation network\"\"\"\n",
        "        self.volume_estimator.eval()\n",
        "        with torch.no_grad():\n",
        "            # Combine all features\n",
        "            features = np.concatenate([\n",
        "                shadow_metrics,  # shadow area, perimeter, direction\n",
        "                tank_dims,       # width, height\n",
        "                sun_position     # altitude, azimuth\n",
        "            ])\n",
        "\n",
        "            # Normalize features\n",
        "            features_normalized = self.scaler.transform(features.reshape(1, -1))\n",
        "            features_tensor = torch.FloatTensor(features_normalized).to(self.device)\n",
        "\n",
        "            # Predict fill percentage\n",
        "            fill_percentage = self.volume_estimator(features_tensor).item()\n",
        "\n",
        "            # Calculate volume in barrels\n",
        "            tank_radius = tank_dims[0] / 2\n",
        "            height_meters = 14  # standard tank height\n",
        "            total_volume = np.pi * (tank_radius ** 2) * height_meters\n",
        "            volume_barrels = total_volume * 6.2898 * fill_percentage\n",
        "\n",
        "            return fill_percentage * 100, volume_barrels\n",
        "\n",
        "    def analyze_image(self, image_path, timestamp):\n",
        "        \"\"\"Main function to analyze satellite image and estimate storage volumes\"\"\"\n",
        "        # Load and preprocess image\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise ValueError(\"Could not load image\")\n",
        "\n",
        "        # Get sun position\n",
        "        sun_alt, sun_az = self.calculate_sun_position(timestamp)\n",
        "\n",
        "        # Detect tanks\n",
        "        tank_locations = self.detect_tanks(image)\n",
        "\n",
        "        if len(tank_locations) == 0:\n",
        "            return pd.DataFrame(columns=['x', 'y', 'width', 'height',\n",
        "                                      'fill_percentage', 'estimated_volume'])\n",
        "\n",
        "        results = []\n",
        "        for location in tank_locations:\n",
        "            try:\n",
        "                # Analyze shadow\n",
        "                shadow_metrics = self.analyze_shadow(image, location, sun_alt, sun_az)\n",
        "\n",
        "                # Estimate volume\n",
        "                tank_dims = location[2:]  # width, height\n",
        "                sun_position = np.array([sun_alt, sun_az])\n",
        "                fill_percentage, volume = self.estimate_volume(\n",
        "                    np.array(shadow_metrics),\n",
        "                    tank_dims,\n",
        "                    sun_position\n",
        "                )\n",
        "\n",
        "                results.append({\n",
        "                    'x': float(location[0]),\n",
        "                    'y': float(location[1]),\n",
        "                    'width': float(location[2]),\n",
        "                    'height': float(location[3]),\n",
        "                    'fill_percentage': float(fill_percentage),\n",
        "                    'estimated_volume': float(volume)\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing tank at location {location}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "def main():\n",
        "    analyzer = MLTankAnalyzer()\n",
        "    # Get current time in UTC\n",
        "    timestamp = datetime.now(pytz.UTC)\n",
        "    image_path = '/content/gas.jpg'\n",
        "\n",
        "    try:\n",
        "        results = analyzer.analyze_image(image_path, timestamp)\n",
        "        central_time = timestamp.astimezone(pytz.timezone('America/Chicago'))\n",
        "        print(f\"Analysis timestamp (Central Time): {central_time}\")\n",
        "        print(f\"Total estimated storage: {results['estimated_volume'].sum():,.0f} barrels\")\n",
        "        print(\"\\nIndividual tank details:\")\n",
        "        print(results.to_string(index=False))\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Analysis failed: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjmpmJjUh4Se",
        "outputId": "6f32cbbd-1559-498f-aa2f-f113cf6e8603"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 207MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing tank at location [[ 0.15552461 -0.02386813  0.02027518  0.14059772]]: not enough values to unpack (expected 4, got 1)\n",
            "Analysis timestamp (Central Time): 2024-12-29 02:28:07.759219-06:00\n",
            "Analysis failed: 'estimated_volume'\n"
          ]
        }
      ]
    }
  ]
}